{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niapy.algorithms.basic import (\n",
    "    BatAlgorithm,\n",
    "    FireflyAlgorithm,\n",
    "    ParticleSwarmAlgorithm\n",
    ")\n",
    "from niapy.runner import Runner\n",
    "from niapy.problems.ackley import Ackley\n",
    "from niapy.problems.sphere import Sphere\n",
    "from niapy.problems.rastrigin import Rastrigin\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pygad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools.ml_tools import get_data_loaders, nn_test, nn_train, LSTM\n",
    "from util.optimization_data import SingleRunData\n",
    "from tools.optimization_tools import optimization_runner\n",
    "from tools.meta_ga import MetaGA\n",
    "\n",
    "from util.constants import (\n",
    "    RNG_SEED,\n",
    "    BATCH_SIZE,\n",
    "    DATASET_PATH,\n",
    "    EPOCHS,\n",
    "    POP_SIZE,\n",
    "    MAX_ITERS,\n",
    "    NUM_RUNS,\n",
    "    OPTIMIZATION_PROBLEM,\n",
    "    GENE_SPACES,\n",
    "    POP_DIVERSITY_METRICS,\n",
    "    INDIV_DIVERSITY_METRICS,\n",
    "    N_PCA_COMPONENTS,\n",
    "    LSTM_NUM_LAYERS,\n",
    "    LSTM_HIDDEN_DIM,\n",
    "    LSTM_DROPOUT,\n",
    "    VAL_SIZE,\n",
    "    TEST_SIZE,\n",
    ")\n",
    "\n",
    "execute_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_0 = pygad.load(\"./archive/2024-06-10_06.55.36_WVCPSO_Trid/meta_ga_obj\")\n",
    "ga_instance_1 = pygad.load(\"./archive/2024-06-10_07.08.39_FA_Trid/meta_ga_obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_0.plot_genes(solutions=\"best\")\n",
    "ga_instance_0.plot_genes(solutions=\"all\")\n",
    "ga_instance_0.plot_new_solution_rate()\n",
    "\n",
    "print(ga_instance_0.best_solutions[-1])\n",
    "print(ga_instance_0.best_solutions_fitness[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_1.plot_genes(solutions=\"best\")\n",
    "ga_instance_1.plot_genes(solutions=\"all\")\n",
    "ga_instance_1.plot_new_solution_rate()\n",
    "\n",
    "print(ga_instance_1.best_solutions[-1])\n",
    "print(ga_instance_1.best_solutions_fitness[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = MetaGA.solution_to_algorithm_attributes(np.concatenate([ga_instance_0.best_solutions[-1], ga_instance_1.best_solutions[-1]]), GENE_SPACES, POP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_problem = Ackley(dimension=20)\n",
    "test_algorithms = [\n",
    "    FireflyAlgorithm(population_size=POP_SIZE, alpha=1.0, beta0=1.0, gamma=0.0, theta=0.99),\n",
    "    ParticleSwarmAlgorithm(population_size=POP_SIZE, c1=0.5, c2=0.5, w=0.75, min_velocity=-np.inf, max_velocity=np.inf),\n",
    "]\n",
    "\n",
    "problem = OPTIMIZATION_PROBLEM\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    optimization_runner(\n",
    "        algorithm=algorithm,\n",
    "        problem=problem,\n",
    "        runs=1,\n",
    "        dataset_path=DATASET_PATH,\n",
    "        pop_diversity_metrics=POP_DIVERSITY_METRICS,\n",
    "        indiv_diversity_metrics=INDIV_DIVERSITY_METRICS,\n",
    "        max_iters=MAX_ITERS,\n",
    "        rng_seed=RNG_SEED,\n",
    "        keep_pop_data=True,\n",
    "        parallel_processing=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        pop_metrics = SingleRunData.import_from_json(run_path).get_pop_diversity_metrics_values(normalize=True)\n",
    "        ax = pop_metrics.plot(title=\" \".join([algorithm, problem]), figsize=(20,5), fontsize=13, logy=True)\n",
    "        ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':13})\n",
    "        ax.set_ylabel(ylabel=\"Value\", fontdict={'fontsize':13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['FA', 'WVCPSO']\n",
    "line_styles = ['-g', ':g', '--g', '-.g', '-b', ':b', '--b', '-.b']\n",
    "_line_styles = ['-g', '-b', '-r', '-k', ':g', ':b', ':r', ':k']\n",
    "style = {}\n",
    "style_idx = 0\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms:\n",
    "        continue\n",
    "    for idx, metric in enumerate(POP_DIVERSITY_METRICS):\n",
    "        if idx > 3:\n",
    "            continue\n",
    "        style['_'.join([algorithm, metric.value])] = line_styles[style_idx]\n",
    "        style_idx += 1\n",
    "\n",
    "metrics_by_problem = {}\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms:\n",
    "        continue\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        pop_metrics = run.get_pop_diversity_metrics_values(normalize=False)\n",
    "        for metric in POP_DIVERSITY_METRICS:\n",
    "            key = '_'.join([algorithm, metric.value])\n",
    "            if problem in metrics_by_problem:\n",
    "                metrics_by_problem[problem][key] = pop_metrics.get(metric.value).to_list()\n",
    "            else:\n",
    "                metric_values = {key: pop_metrics.get(metric.value).to_list()}\n",
    "                metrics_by_problem[problem] = metric_values\n",
    "        \n",
    "\n",
    "for problem in metrics_by_problem:\n",
    "    metrics = metrics_by_problem[problem]\n",
    "    df_metrics = pd.DataFrame.from_dict(metrics)\n",
    "    df_metrics.plot(style=style, figsize=(25, 7), logy=True, title=problem, xlabel=\"Iterations\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best fitness value convergence comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergences = {}\n",
    "max_len = 0\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        print(f\"best fitness {algorithm} - {problem}: {run.best_fitness}\")\n",
    "        #print(f\"best solution {algorithm} - {problem}: {run.best_solution}\")\n",
    "        convergence = run.get_best_fitness_values(normalize=False)\n",
    "        if len(convergence) > max_len:\n",
    "            max_len = len(convergence)\n",
    "        \n",
    "        if problem in convergences:\n",
    "            convergences[problem][algorithm] = convergence\n",
    "        else:\n",
    "            convergence_dict = {algorithm: convergence}\n",
    "            convergences[problem] = convergence_dict\n",
    "\n",
    "for problem in convergences:\n",
    "    convergence_dict = convergences[problem]\n",
    "    for key in convergence_dict:\n",
    "        convergence = convergence_dict[key]\n",
    "        convergence = np.append(convergence, [convergence[-1]] * (max_len - len(convergence)))\n",
    "        convergence_dict[key] = convergence\n",
    "\n",
    "    convergence_dict = pd.DataFrame.from_dict(convergence_dict)\n",
    "    convergence_dict.plot(title=problem, figsize=(25, 7), logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_problem = {}\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms:\n",
    "        continue\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        indiv_metrics = run.get_indiv_diversity_metrics_values(normalize=False)\n",
    "        for metric in INDIV_DIVERSITY_METRICS:\n",
    "            key = '_'.join([algorithm, metric.value])\n",
    "            if problem in metrics_by_problem:\n",
    "                metrics_by_problem[problem][key] = indiv_metrics.get(metric.value).to_list()\n",
    "            else:\n",
    "                metric_values = {key: indiv_metrics.get(metric.value).to_list()}\n",
    "                metrics_by_problem[problem] = metric_values\n",
    "        \n",
    "\n",
    "for problem in metrics_by_problem:\n",
    "    metrics = metrics_by_problem[problem]\n",
    "    df_metrics = pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(INDIV_DIVERSITY_METRICS))\n",
    "    fig.suptitle(problem, fontsize=23)\n",
    "\n",
    "    for idx, metric in enumerate(INDIV_DIVERSITY_METRICS):\n",
    "        df_selected_metric = df_metrics.filter(regex=metric.value)\n",
    "        df_selected_metric.columns = df_selected_metric.columns.str.replace('_'+metric.value, '')\n",
    "        df_selected_metric.plot(ax=axes[idx], kind=\"box\", figsize=(25, 6), logy=False, title=metric.name, fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        indiv_metrics = SingleRunData.import_from_json(run_path).get_indiv_diversity_metrics_values(normalize=True)\n",
    "        indiv_metrics.plot(title=\" \".join([algorithm, problem]), figsize=(25, 7), kind=\"bar\", logy=True)\n",
    "\n",
    "        indiv_metrics = indiv_metrics.to_numpy()\n",
    "        pca = PCA(n_components=N_PCA_COMPONENTS)\n",
    "        principal_components = pca.fit_transform(indiv_metrics)\n",
    "        variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity metrics euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srd = []\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd.append(SingleRunData.import_from_json(run_path))\n",
    "\n",
    "print(srd[0].diversity_metrics_euclidean_distance(srd[1]))\n",
    "print(srd[0].diversity_metrics_euclidean_distance(srd[1], include_fitness_convergence=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(\"CPUs: \", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, val_data_loader, test_data_loader, labels = get_data_loaders(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    val_size=VAL_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "    n_pca_components=N_PCA_COMPONENTS,\n",
    "    problems=[OPTIMIZATION_PROBLEM.name()],\n",
    "    random_state=RNG_SEED,\n",
    ")\n",
    "\n",
    "pop_features, indiv_features, target = next(iter(train_data_loader))\n",
    "model = LSTM(\n",
    "    input_dim=np.shape(pop_features)[2],\n",
    "    aux_input_dim=np.shape(indiv_features)[1],\n",
    "    num_labels=len(labels),\n",
    "    hidden_dim=LSTM_HIDDEN_DIM,\n",
    "    num_layers=LSTM_NUM_LAYERS,\n",
    "    dropout=LSTM_DROPOUT\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_filename = f\"./lstm_model.pt\"\n",
    "\n",
    "if execute_training:\n",
    "    model.to(device)\n",
    "    nn_train(\n",
    "        model=model,\n",
    "        train_data_loader=train_data_loader,\n",
    "        val_data_loader=val_data_loader,\n",
    "        epochs=EPOCHS,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        model_filename=model_filename,\n",
    "        verbal=True)\n",
    "else:\n",
    "    model = torch.load(model_filename, map_location=torch.device(device))\n",
    "    model.to(device)\n",
    "    if os.path.exists('loss_plot.png'):\n",
    "        loss_plot = np.asarray(Image.open('loss_plot.png'))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test(model, test_data_loader, device, labels=labels, show_classification_report=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
