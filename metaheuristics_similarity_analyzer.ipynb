{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niapy.algorithms.basic import (\n",
    "    BatAlgorithm,\n",
    "    FireflyAlgorithm,\n",
    "    ParticleSwarmAlgorithm\n",
    ")\n",
    "from niapy.problems.ackley import Ackley\n",
    "from niapy.problems.sphere import Sphere\n",
    "from niapy.runner import Runner\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pygad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools.ml_tools import get_data_loaders, nn_test, nn_train, LSTM\n",
    "from util.optimization_data import SingleRunData\n",
    "from tools.optimization_tools import optimization_runner\n",
    "from meta_ga import solution_to_algorithm_attributes, meta_ga_info\n",
    "\n",
    "from util.constants import (\n",
    "    RNG_SEED,\n",
    "    BATCH_SIZE,\n",
    "    DATASET_PATH,\n",
    "    EPOCHS,\n",
    "    POP_SIZE,\n",
    "    MAX_ITERS,\n",
    "    NUM_RUNS,\n",
    "    OPTIMIZATION_PROBLEM,\n",
    "    GENE_SPACES,\n",
    "    POP_DIVERSITY_METRICS,\n",
    "    INDIV_DIVERSITY_METRICS,\n",
    "    N_PCA_COMPONENTS,\n",
    "    LSTM_NUM_LAYERS,\n",
    "    LSTM_HIDDEN_DIM,\n",
    "    LSTM_DROPOUT,\n",
    "    VAL_SIZE,\n",
    "    TEST_SIZE,\n",
    ")\n",
    "\n",
    "meta_ga_info()\n",
    "\n",
    "execute_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance = pygad.load(\"meta_ga_obj\")\n",
    "print(ga_instance.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ga_instance.plot_genes(solutions=\"best\")\n",
    "print(ga_instance.best_solutions[-1])\n",
    "print(ga_instance.best_solutions_fitness[-1])\n",
    "\n",
    "algorithms = solution_to_algorithm_attributes(ga_instance.best_solutions[-1], GENE_SPACES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_problem = Ackley(dimension=20)\n",
    "test_algorithms = [\n",
    "    #BatAlgorithm(population_size=POP_SIZE, alpha=0.99, gamma=0.9, pulse_rate=0.9, loudness=0.9),\n",
    "    FireflyAlgorithm(population_size=POP_SIZE, alpha=1.0, beta0=1.0, gamma=0.00),\n",
    "    ParticleSwarmAlgorithm(population_size=POP_SIZE, c1=0.5, c2=0.5, w=0.75, min_velocity=-10.0, max_velocity=10.0),\n",
    "]\n",
    "\n",
    "problem = OPTIMIZATION_PROBLEM\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    optimization_runner(\n",
    "        algorithm=algorithm,\n",
    "        problem=problem,\n",
    "        runs=1,\n",
    "        dataset_path=DATASET_PATH,\n",
    "        pop_diversity_metrics=POP_DIVERSITY_METRICS,\n",
    "        indiv_diversity_metrics=INDIV_DIVERSITY_METRICS,\n",
    "        max_iters=MAX_ITERS,\n",
    "        rng_seed=RNG_SEED,\n",
    "        keep_pop_data=True,\n",
    "        parallel_processing=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        pop_metrics = SingleRunData.import_from_json(run_path).get_pop_diversity_metrics_values(normalize=True)\n",
    "        ax = pop_metrics.plot(title=\" \".join([algorithm, problem]), figsize=(20,5), fontsize=13)\n",
    "        ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':13})\n",
    "        ax.set_ylabel(ylabel=\"Value\", fontdict={'fontsize':13})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best fitness value convergence comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_dict = {}\n",
    "max_len = 0\n",
    "algorithms = []\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    algorithms.append(algorithm)\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        convergence = SingleRunData.import_from_json(run_path).get_best_fitness_values(normalize=False)\n",
    "        if len(convergence) > max_len:\n",
    "            max_len = len(convergence)\n",
    "        convergence_dict[\"_\".join([algorithm, problem])] = convergence\n",
    "\n",
    "for key in convergence_dict:\n",
    "    convergence = convergence_dict[key]\n",
    "    print(f\"best fitness {key}: {convergence[-1]}\")\n",
    "    convergence = np.append(convergence, [convergence[-1]] * (max_len - len(convergence)))\n",
    "    convergence_dict[key] = convergence\n",
    "\n",
    "convergence_dict = pd.DataFrame.from_dict(convergence_dict)\n",
    "convergence_dict.plot(title=\" \".join([*algorithms, problem]), figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        indiv_metrics = SingleRunData.import_from_json(run_path).get_indiv_diversity_metrics_values(normalize=True)\n",
    "        #indiv_metrics.plot(title=\" \".join([algorithm, problem]), figsize=(20,5), kind=\"bar\")\n",
    "\n",
    "        indiv_metrics = indiv_metrics.to_numpy()\n",
    "        pca = PCA(n_components=N_PCA_COMPONENTS)\n",
    "        principal_components = pca.fit_transform(indiv_metrics)\n",
    "        variance = pca.explained_variance_ratio_\n",
    "\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(principal_components[:,0], principal_components[:,1], principal_components[:,2], color = \"green\")\n",
    "        ax.set_xlabel(xlabel=\"PC1\", fontdict={'fontsize':13})\n",
    "        ax.set_ylabel(ylabel=\"PC2\", fontdict={'fontsize':13})\n",
    "        ax.set_zlabel(zlabel=\"PC3\", fontdict={'fontsize':13})\n",
    "        ax.set_xlim((-1.0,1.0))\n",
    "        ax.set_ylim((1.0,-1.0))\n",
    "        ax.set_zlim((-1.0,1.0))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity metrics euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srd = []\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd.append(SingleRunData.import_from_json(run_path))\n",
    "\n",
    "print(srd[0].diversity_metrics_euclidean_distance(srd[1]))\n",
    "print(srd[0].diversity_metrics_euclidean_distance(srd[1], include_fitness_convergence=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(\"CPUs: \", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, val_data_loader, test_data_loader, labels = get_data_loaders(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    val_size=VAL_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "    n_pca_components=N_PCA_COMPONENTS,\n",
    "    problems=[OPTIMIZATION_PROBLEM.name()],\n",
    "    random_state=RNG_SEED,\n",
    ")\n",
    "\n",
    "pop_features, indiv_features, target = next(iter(train_data_loader))\n",
    "model = LSTM(\n",
    "    input_dim=np.shape(pop_features)[2],\n",
    "    aux_input_dim=np.shape(indiv_features)[1],\n",
    "    num_labels=len(labels),\n",
    "    hidden_dim=LSTM_HIDDEN_DIM,\n",
    "    num_layers=LSTM_NUM_LAYERS,\n",
    "    dropout=LSTM_DROPOUT\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_file_name = f\"./lstm_model.pt\"\n",
    "\n",
    "if execute_training:\n",
    "    model.to(device)\n",
    "    nn_train(model, train_data_loader, val_data_loader, EPOCHS, loss_fn, optimizer, device, model_file_name, verbal=True)\n",
    "else:\n",
    "    model = torch.load(model_file_name, map_location=torch.device(device))\n",
    "    model.to(device)\n",
    "    if os.path.exists('loss_plot.png'):\n",
    "        loss_plot = np.asarray(Image.open('loss_plot.png'))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test(model, test_data_loader, device, labels=labels, show_classification_report=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
