{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "CPUs:  12\n"
     ]
    }
   ],
   "source": [
    "from niapy.algorithms.basic import (\n",
    "    BatAlgorithm,\n",
    "    ParticleSwarmAlgorithm,\n",
    "    ParticleSwarmOptimization,\n",
    ")\n",
    "from tools.algorithms.fa import FireflyAlgorithm\n",
    "from niapy.problems.ackley import Ackley\n",
    "from niapy.problems.bent_cigar import BentCigar\n",
    "from niapy.problems.sphere import Sphere\n",
    "from niapy.problems.schwefel import Schwefel, Schwefel222\n",
    "from niapy.problems.rastrigin import Rastrigin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "from scipy import spatial\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pygad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tools.ml_tools import get_data_loaders, nn_test, nn_train, NNType, LSTMClassifier, LinearClassifier\n",
    "from util.optimization_data import SingleRunData\n",
    "from util.pop_diversity_metrics import PopDiversityMetric\n",
    "from tools.optimization_tools import optimization_runner\n",
    "from tools.meta_ga import MetaGA, MetaGAFitnessFunction\n",
    "from tools.metaheuristic_similarity_analyzer import MetaheuristicSimilarityAnalyzer\n",
    "\n",
    "from util.constants import (\n",
    "    RNG_SEED,\n",
    "    BATCH_SIZE,\n",
    "    DATASET_PATH,\n",
    "    EPOCHS,\n",
    "    POP_SIZE,\n",
    "    MAX_ITERS,\n",
    "    MAX_EVALS,\n",
    "    NUM_RUNS,\n",
    "    OPTIMIZATION_PROBLEM,\n",
    "    META_GA_CROSSOVER_PROBABILITY,\n",
    "    META_GA_CROSSOVER_TYPE,\n",
    "    META_GA_GENERATIONS,\n",
    "    META_GA_K_TOURNAMENT,\n",
    "    META_GA_KEEP_ELITISM,\n",
    "    META_GA_MUTATION_NUM_GENES,\n",
    "    META_GA_MUTATION_TYPE,\n",
    "    META_GA_PARENT_SELECTION_TYPE,\n",
    "    META_GA_PERCENT_PARENTS_MATING,\n",
    "    META_GA_SOLUTIONS_PER_POP,\n",
    "    GENE_SPACES,\n",
    "    TARGET_GENE_SPACES,\n",
    "    POP_DIVERSITY_METRICS,\n",
    "    INDIV_DIVERSITY_METRICS,\n",
    "    N_PCA_COMPONENTS,\n",
    "    LSTM_NUM_LAYERS,\n",
    "    LSTM_HIDDEN_DIM,\n",
    "    LSTM_DROPOUT,\n",
    "    VAL_SIZE,\n",
    "    TEST_SIZE,\n",
    ")\n",
    "\n",
    "DATASET_PATH = \"./archive/target_performance_similarity/09-17_15.37.29_WVCPSO_Schwefel/dataset/0_subset\"\n",
    "\n",
    "algorithms_to_plot = ['FA', 'WVCPSO', 'PSO']\n",
    "\n",
    "execute_training = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(\"CPUs: \", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9758951945778113, 0.9444098228289451, 0.9685555405179425, 0.9961127817660602, 0.9841942448904325, 0.9958329904899021, 0.9925717943835706, 0.9795050504085272, 0.9955789972956697, 0.9900625424281313, 0.9671113247363249, 0.9543454694089516, 0.7814385119635219, 0.9827782654805161, 0.9979705758074211, 0.9859355053312998, 0.9880394430958183, 0.997039442898456, 0.9902485707996629, 0.9977444798815096, 0.998165499883075, 0.9508605029517587, 0.995964298403001, 0.8822917498696059, 0.6794349790139599, 0.9802577239382497, 0.9780038193251145, 0.9953200264371361, 0.9956229311274402, 0.9990439251929232] \n",
      "\n",
      "[1.56 1.59 0.06]\n",
      "[2.12 0.18 0.55]\n",
      "[0.18 1.4  0.36]\n",
      "[1.23 1.49 0.83]\n",
      "[1.69 2.4  0.92]\n",
      "[1.42 0.89 0.97]\n",
      "[2.37 1.84 0.63]\n",
      "[1.79 0.42 0.19]\n",
      "[0.83 1.44 0.72]\n",
      "[0.88 0.37 0.41]\n",
      "[0.2  1.6  0.47]\n",
      "[1.41 0.01 0.97]\n",
      "[1.95 1.45 0.5 ]\n",
      "[0.35 0.07 0.72]\n",
      "[0.66 0.17 0.01]\n",
      "[0.1  1.16 0.58]\n",
      "[2.24 0.08 0.4 ]\n",
      "[2.   0.22 0.41]\n",
      "[2.04 1.67 0.94]\n",
      "[0.75 2.28 0.53]\n",
      "[0.19 0.86 0.9 ]\n",
      "[0.29 1.15 0.57]\n",
      "[0.48 0.24 0.65]\n",
      "[0.41 1.61 0.24]\n",
      "[0.74 1.01 0.75]\n",
      "[2.12 0.52 0.19]\n",
      "[2.34 0.41 0.21]\n",
      "[0.78 1.33 0.67]\n",
      "[0.77 1.05 0.1 ]\n",
      "[0.76 1.8  0.55]\n",
      "\n",
      "[1.8  1.63 0.01]\n",
      "[1.29 0.15 0.83]\n",
      "[0.36 1.32 0.37]\n",
      "[1.63 0.91 0.82]\n",
      "[2.45 1.87 0.77]\n",
      "[1.37 0.9  0.95]\n",
      "[2.27 2.   0.57]\n",
      "[1.54 0.35 0.5 ]\n",
      "[0.89 1.42 0.72]\n",
      "[0.98 0.4  0.4 ]\n",
      "[0.31 1.67 0.47]\n",
      "[2.48 0.01 0.86]\n",
      "[2.22 1.59 0.14]\n",
      "[0.41 0.08 0.77]\n",
      "[0.6  0.17 0.13]\n",
      "[0.01 1.57 0.5 ]\n",
      "[1.65 0.05 0.76]\n",
      "[2.13 0.26 0.25]\n",
      "[2.31 2.06 0.91]\n",
      "[0.99 2.48 0.46]\n",
      "[0.12 0.39 0.94]\n",
      "[0.28 1.48 0.47]\n",
      "[0.29 0.17 0.76]\n",
      "[0.31 1.43 0.29]\n",
      "[1.82 1.09 0.36]\n",
      "[2.22 0.52 0.35]\n",
      "[2.28 0.41 0.48]\n",
      "[0.79 0.97 0.77]\n",
      "[0.92 1.09 0.07]\n",
      "[0.73 1.75 0.58]\n",
      "min:  0.01 & 0.01 & 0.01 & 0.1 & 0.01 & 0.01\n",
      "avg:  1.25 & 1.01 & 0.54 & 1.16 & 1.02 & 0.53\n",
      "max:  2.48 & 2.48 & 0.95 & 2.37 & 2.4 & 0.97\n",
      "std:  0.8 & 0.71 & 0.27 & 0.74 & 0.68 & 0.28\n"
     ]
    }
   ],
   "source": [
    "analyzer = MetaheuristicSimilarityAnalyzer.import_from_pkl(\"./archive/target_performance_similarity/09-17_15.37.29_WVCPSO_Schwefel/msa_obj\")\n",
    "print(analyzer.similarity, \"\\n\")\n",
    "for solution in analyzer.optimized_solutions:\n",
    "    print(solution)\n",
    "print(\"\")\n",
    "for solution in analyzer.target_solutions:\n",
    "    print(solution)\n",
    "\n",
    "print(\"min: \", \" & \".join(map(str, np.round(np.min(np.array(analyzer.target_solutions), axis=0), 2))), \"&\", \" & \".join(map(str, np.round(np.min(np.array(analyzer.optimized_solutions), axis=0), 2))))\n",
    "print(\"avg: \", \" & \".join(map(str, np.round(np.mean(np.array(analyzer.target_solutions), axis=0), 2))), \"&\", \" & \".join(map(str, np.round(np.mean(np.array(analyzer.optimized_solutions), axis=0), 2))))\n",
    "print(\"max: \", \" & \".join(map(str, np.round(np.max(np.array(analyzer.target_solutions), axis=0), 2))), \"&\", \" & \".join(map(str, np.round(np.max(np.array(analyzer.optimized_solutions), axis=0), 2))))\n",
    "print(\"std: \", \" & \".join(map(str, np.round(np.std(np.array(analyzer.target_solutions), axis=0), 2))), \"&\", \" & \".join(map(str, np.round(np.std(np.array(analyzer.optimized_solutions), axis=0), 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_0 = pygad.load(\"./archive/target_performance_similarity/08-01_14.42.43_WVCPSO_Schwefel/0_FA_Schwefel/meta_ga_obj\")\n",
    "ga_instance_1 = pygad.load(\"./archive/target_performance_similarity/08-01_14.42.43_WVCPSO_Schwefel/0_FA_Schwefel/meta_ga_obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_0.plot_genes(solutions=\"best\")\n",
    "ga_instance_0.plot_genes(solutions=\"all\")\n",
    "ga_instance_0.plot_new_solution_rate()\n",
    "\n",
    "print(ga_instance_0.best_solutions[-1])\n",
    "print(ga_instance_0.best_solutions_fitness[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_1.plot_genes(solutions=\"best\")\n",
    "ga_instance_1.plot_genes(solutions=\"all\")\n",
    "ga_instance_1.plot_new_solution_rate()\n",
    "\n",
    "print(ga_instance_1.best_solutions[-1])\n",
    "print(ga_instance_1.best_solutions_fitness[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = MetaGA.solution_to_algorithm_attributes(np.concatenate([ga_instance_0.best_solutions[-1], ga_instance_1.best_solutions[-1]]), GENE_SPACES, POP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_test_setting = True\n",
    "\n",
    "problem = OPTIMIZATION_PROBLEM\n",
    "\n",
    "if use_test_setting:\n",
    "    problem = Schwefel(dimension=20)\n",
    "    algorithms = [\n",
    "        #FireflyAlgorithm(population_size=POP_SIZE, alpha=0.239739118, beta0=0.685364775, gamma=0.000244544267, theta=0.996317628),\n",
    "        #FireflyAlgorithm(population_size=POP_SIZE, alpha=0.84464886, beta0=0.74171366, gamma=0.60686203, theta=0.97758844),\n",
    "        FireflyAlgorithm(population_size=POP_SIZE, alpha=0.01, beta0=0.43, gamma=0.693, theta=0.962),\n",
    "        #ParticleSwarmAlgorithm(population_size=POP_SIZE, c1=1.14, c2=0.05, w=0.54),\n",
    "        #ParticleSwarmAlgorithm(population_size=POP_SIZE, c1=2.00417841, c2=0.70674774, w=0.82266951),\n",
    "        #ParticleSwarmAlgorithm(population_size=POP_SIZE, c1=1.35776463, c2=1.7283054, w=0.58735118, min_velocity=-93.37297714, max_velocity=55.94034227),\n",
    "    ]\n",
    "\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    optimization_runner(\n",
    "        algorithm=algorithm,\n",
    "        problem=problem,\n",
    "        runs=NUM_RUNS,\n",
    "        dataset_path=\"./dataset\",\n",
    "        pop_diversity_metrics=POP_DIVERSITY_METRICS,\n",
    "        indiv_diversity_metrics=INDIV_DIVERSITY_METRICS,\n",
    "        max_evals=MAX_EVALS,\n",
    "        run_index_seed=True,\n",
    "        keep_pop_data=False,\n",
    "        parallel_processing=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_metrics_list = [\n",
    "    PopDiversityMetric.FDC,\n",
    "    PopDiversityMetric.PDC,\n",
    "    PopDiversityMetric.PFSD,\n",
    "    PopDiversityMetric.PFMea,\n",
    "]\n",
    "\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        print(f\"best fitness {algorithm} - {problem}: {srd.best_fitness}\")\n",
    "        pop_metrics = SingleRunData.import_from_json(run_path).get_pop_diversity_metrics_values(metrics=pop_metrics_list, normalize=True)\n",
    "        ax = pop_metrics.plot(figsize=(25,7), fontsize=15, logy=False)\n",
    "        ax.set_title(label=\" \".join([algorithm, problem]), fontdict={'fontsize':24})\n",
    "        ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':20})\n",
    "        ax.set_ylabel(ylabel=\"Value\", fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vectors comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pop_metrics_list = [\n",
    "    PopDiversityMetric.AAD,\n",
    "    PopDiversityMetric.FDC,\n",
    "    PopDiversityMetric.PDC,\n",
    "    PopDiversityMetric.PFSD,\n",
    "    PopDiversityMetric.PFMea,\n",
    "]\n",
    "\n",
    "for i in range(50):\n",
    "    _dataset_path = f\"./archive/target_performance_similarity/07-29_22.48.39_WVCPSO_Schwefel/0_FA_Schwefel/meta_ga_tmp_data/{i}_meta_dataset\"\n",
    "    feature_vectors = []\n",
    "    for idx, algorithm in enumerate(os.listdir(_dataset_path)):\n",
    "        for problem in os.listdir(os.path.join(_dataset_path, algorithm)):\n",
    "            runs = os.listdir(os.path.join(_dataset_path, algorithm, problem))\n",
    "            runs.sort()\n",
    "            for j, run in enumerate(runs):\n",
    "                if i == 20:\n",
    "                    print(j)\n",
    "                run_path = os.path.join(_dataset_path, algorithm, problem, run)\n",
    "                srd = SingleRunData.import_from_json(run_path)\n",
    "                feature_vector = srd.get_combined_feature_vector()\n",
    "                \n",
    "                feature_vectors.append(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_metrics_list = [\n",
    "    PopDiversityMetric.AAD,\n",
    "    PopDiversityMetric.FDC,\n",
    "    PopDiversityMetric.PDC,\n",
    "    PopDiversityMetric.PFSD,\n",
    "    PopDiversityMetric.PFMea,\n",
    "]\n",
    "\n",
    "\n",
    "feature_vectors_list = []\n",
    "\n",
    "feature_vectors_1 = []\n",
    "feature_vectors_2 = []\n",
    "for idx, algorithm in enumerate(os.listdir(DATASET_PATH)):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        for run in runs:\n",
    "            run_path = os.path.join(DATASET_PATH, algorithm, problem, run)\n",
    "            srd = SingleRunData.import_from_json(run_path)\n",
    "            feature_vector = srd.get_combined_feature_vector()\n",
    "            #pop_metrics = SingleRunData.import_from_json(run_path).get_pop_diversity_metrics_values(metrics=pop_metrics_list, normalize=True)\n",
    "            #ax = pop_metrics.plot(figsize=(25,7), fontsize=15, logy=False)\n",
    "            #ax.set_title(label=\" \".join([algorithm, problem]), fontdict={'fontsize':24})\n",
    "            #ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':20})\n",
    "            #ax.set_ylabel(ylabel=\"Value\", fontdict={'fontsize':20})\n",
    "\n",
    "            if idx == 0:\n",
    "                feature_vectors_1.append(feature_vector)\n",
    "            else:\n",
    "                feature_vectors_2.append(feature_vector)\n",
    "\n",
    "feature_vectors_list.append(feature_vectors_1)\n",
    "feature_vectors_list.append(feature_vectors_2)\n",
    "\n",
    "# similarity plot for variable number of vectors\n",
    "mean_similarities = []\n",
    "for i in range(2, len(feature_vectors_1)):\n",
    "    mean_vector_1 = np.mean(feature_vectors_1[:i], axis=0)\n",
    "    mean_vector_2 = np.mean(feature_vectors_2[:i], axis=0)\n",
    "    mean_similarities.append(1 - spatial.distance.cosine(mean_vector_1, mean_vector_2))\n",
    "\n",
    "mean_pairwise_similarities = []\n",
    "for i in range(2, len(feature_vectors_1)):\n",
    "    similarities = []\n",
    "    for feature_vector1, feature_vector2 in zip(feature_vectors_1[:i], feature_vectors_2[:i]):\n",
    "        similarities.append(1 - spatial.distance.cosine(feature_vector1, feature_vector2))\n",
    "\n",
    "    mean_pairwise_similarities.append(np.mean(similarities))\n",
    "\n",
    "mean_pairwise_total_similarities = []\n",
    "for i in range(2, len(feature_vectors_1)):\n",
    "    total_sum = 0\n",
    "    for idx_1 in range(len(feature_vectors_1[:i])):\n",
    "        sum = 0\n",
    "        for idx_2 in range(len(feature_vectors_2[:i])):\n",
    "            if idx_1 == idx_2:\n",
    "                continue\n",
    "            sum += 1 - spatial.distance.cosine(feature_vectors_1[idx_1], feature_vectors_2[idx_2])\n",
    "        total_sum += sum/(len(feature_vectors_2[:i]) - 1)\n",
    "    mean_pairwise_total_similarities.append(total_sum/(len(feature_vectors_2[:i]) - 1))\n",
    "\n",
    "plt.plot(np.arange(0, len(mean_pairwise_total_similarities)), mean_pairwise_total_similarities)\n",
    "plt.plot(np.arange(0, len(mean_pairwise_similarities)), mean_pairwise_similarities)\n",
    "plt.plot(np.arange(0, len(mean_similarities)), mean_similarities)\n",
    "plt.show()\n",
    "\n",
    "# plot mean vectors for visual comparison\n",
    "mean_vector_1 = np.mean(feature_vectors_1, axis=0)\n",
    "mean_vector_2 = np.mean(feature_vectors_2, axis=0)\n",
    "plt.plot(np.arange(0, len(mean_vector_1)), mean_vector_1)\n",
    "plt.plot(np.arange(0, len(mean_vector_2)), mean_vector_2)\n",
    "plt.show()\n",
    "print(1 - spatial.distance.cosine(mean_vector_1, mean_vector_2), \"\\n\")\n",
    "\n",
    "total_sum = 0\n",
    "for idx_1 in range(len(feature_vectors_1)):\n",
    "    sum = 0\n",
    "    for idx_2 in range(len(feature_vectors_2)):\n",
    "        if idx_1 == idx_2:\n",
    "            continue\n",
    "        #print(f\"{idx_1} : {1 - spatial.distance.cosine(feature_vectors_2[idx_1], feature_vectors_2[idx_2])}\")\n",
    "        sum += 1 - spatial.distance.cosine(feature_vectors_1[idx_1], feature_vectors_2[idx_2])\n",
    "    total_sum += sum/(len(feature_vectors_2) - 1)\n",
    "print(\"total similarity: \", total_sum/(len(feature_vectors_2) - 1))\n",
    "\n",
    "similarities = []\n",
    "for feature_vector1, feature_vector2 in zip(feature_vectors_1, feature_vectors_2):\n",
    "    #print(1 - spatial.distance.cosine(feature_vector1, feature_vector2))\n",
    "    similarities.append(1 - spatial.distance.cosine(feature_vector1, feature_vector2))\n",
    "\n",
    "print(\"pairwise similarity\",np.mean(similarities))\n",
    "\n",
    "for vector_idx in range(4):\n",
    "    plt.plot(np.arange(0, len(feature_vectors_1[vector_idx])), feature_vectors_1[vector_idx])\n",
    "    plt.plot(np.arange(0, len(feature_vectors_2[vector_idx])), feature_vectors_2[vector_idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FDC comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdc_values = {}\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms_to_plot:\n",
    "        continue\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        metrics = run.get_pop_diversity_metrics_values(metrics=[PopDiversityMetric.FDC], normalize=False)\n",
    "        if len(metrics) == 0:\n",
    "            continue\n",
    "        fdc = metrics.get(\"fdc\")\n",
    "        \n",
    "        if problem in fdc_values:\n",
    "            fdc_values[problem][algorithm] = fdc\n",
    "        else:\n",
    "            fdc_dict = {algorithm: fdc}\n",
    "            fdc_values[problem] = fdc_dict\n",
    "\n",
    "for problem in fdc_values:\n",
    "    fdc_dict = fdc_values[problem]\n",
    "    for key in fdc_dict:\n",
    "        convergence = fdc_dict[key]\n",
    "        fdc_dict[key] = convergence\n",
    "\n",
    "    fdc_dict = pd.DataFrame.from_dict(fdc_dict)\n",
    "    ax = fdc_dict.plot(title=problem, figsize=(25, 7), logy=False, fontsize=15)\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_title(label=problem, fontdict={'fontsize':24})\n",
    "    ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_styles = ['-g', ':g', '--g', '-.g', '-b', ':b', '--b', '-.b']\n",
    "_line_styles = ['-g', '-b', '-r', '-k', ':g', ':b', ':r', ':k']\n",
    "style = {}\n",
    "pop_metrics_list = [\n",
    "    PopDiversityMetric.FDC,\n",
    "    PopDiversityMetric.PDC,\n",
    "    PopDiversityMetric.PFSD,\n",
    "    PopDiversityMetric.PFMea,\n",
    "]\n",
    "style_idx = 0\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms_to_plot:\n",
    "        continue\n",
    "    for idx, metric in enumerate(pop_metrics_list):\n",
    "        if idx > 3:\n",
    "            continue\n",
    "        style['_'.join([algorithm, metric.value])] = line_styles[style_idx]\n",
    "        style_idx += 1\n",
    "\n",
    "metrics_by_problem = {}\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms_to_plot:\n",
    "        continue\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        pop_metrics = run.get_pop_diversity_metrics_values(metrics=pop_metrics_list, normalize=False)\n",
    "        #if \"fdc\" in pop_metrics:\n",
    "        #    pop_metrics.drop(columns=[\"fdc\"], inplace=True)\n",
    "        for metric in pop_metrics_list:\n",
    "            key = '_'.join([algorithm, metric.value])\n",
    "            if metric.value not in pop_metrics:\n",
    "                continue\n",
    "            if problem in metrics_by_problem:\n",
    "                metrics_by_problem[problem][key] = pop_metrics.get(metric.value).to_list()\n",
    "            else:\n",
    "                metric_values = {key: pop_metrics.get(metric.value).to_list()}\n",
    "                metrics_by_problem[problem] = metric_values\n",
    "        \n",
    "\n",
    "for problem in metrics_by_problem:\n",
    "    metrics = metrics_by_problem[problem]\n",
    "    df_metrics = pd.DataFrame.from_dict(metrics)\n",
    "    ax = df_metrics.plot(style=style, figsize=(25, 7), logy=True, fontsize=15)\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_title(label=problem, fontdict={'fontsize':24})\n",
    "    ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best fitness value convergence comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergences = {}\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms_to_plot:\n",
    "        continue\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        print(f\"best fitness {algorithm} - {problem}: {run.best_fitness}\")\n",
    "        convergence = run.get_best_fitness_values(normalize=False)\n",
    "        \n",
    "        if problem in convergences:\n",
    "            convergences[problem][algorithm] = convergence\n",
    "        else:\n",
    "            convergence_dict = {algorithm: convergence}\n",
    "            convergences[problem] = convergence_dict\n",
    "\n",
    "for problem in convergences:\n",
    "    convergence_dict = convergences[problem]\n",
    "    for key in convergence_dict:\n",
    "        convergence = convergence_dict[key]\n",
    "        convergence_dict[key] = convergence\n",
    "\n",
    "    convergence_dict = pd.DataFrame.from_dict(convergence_dict)\n",
    "    ax = convergence_dict.plot(title=problem, figsize=(25, 7), logy=False, fontsize=15)\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_title(label=problem, fontdict={'fontsize':24})\n",
    "    ax.set_xlabel(xlabel=\"Iterations\", fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_problem = {}\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    if algorithm not in algorithms_to_plot:\n",
    "        continue\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        run = SingleRunData.import_from_json(run_path)\n",
    "        indiv_metrics = run.get_indiv_diversity_metrics_values(normalize=False)\n",
    "        for metric in INDIV_DIVERSITY_METRICS:\n",
    "            key = '_'.join([algorithm, metric.value])\n",
    "            if problem in metrics_by_problem:\n",
    "                metrics_by_problem[problem][key] = indiv_metrics.get(metric.value).to_list()\n",
    "            else:\n",
    "                metric_values = {key: indiv_metrics.get(metric.value).to_list()}\n",
    "                metrics_by_problem[problem] = metric_values\n",
    "        \n",
    "\n",
    "for problem in metrics_by_problem:\n",
    "    metrics = metrics_by_problem[problem]\n",
    "    df_metrics = pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(INDIV_DIVERSITY_METRICS))\n",
    "    fig.suptitle(problem, fontsize=23)\n",
    "\n",
    "    for idx, metric in enumerate(INDIV_DIVERSITY_METRICS):\n",
    "        df_metric = df_metrics.filter(regex=metric.value)\n",
    "        df_metric.columns = df_metric.columns.str.replace('_'+metric.value, '')\n",
    "        ax = df_metric.plot(ax=axes[idx], kind=\"box\", figsize=(25, 6), logy=False, fontsize=15)\n",
    "        ax.set_title(label=metric.name, fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        runs.sort()\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        indiv_metrics = SingleRunData.import_from_json(run_path).get_indiv_diversity_metrics_values(normalize=True)\n",
    "        ax = indiv_metrics.plot(figsize=(25, 7), kind=\"bar\", logy=True, fontsize=20, rot=0)\n",
    "        ax.legend(fontsize=15)\n",
    "        ax.set_title(label=\" \".join([algorithm, problem]), fontdict={'fontsize':24})\n",
    "        ax.set_xlabel(xlabel=\"Individuals\", fontdict={'fontsize':20})\n",
    "\n",
    "        indiv_metrics = indiv_metrics.to_numpy()\n",
    "        pca = PCA(n_components=N_PCA_COMPONENTS)\n",
    "        principal_components = pca.fit_transform(indiv_metrics)\n",
    "        variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN training and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, val_data_loader, test_data_loader, actual_labels = get_data_loaders(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    val_size=VAL_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "    n_pca_components=N_PCA_COMPONENTS,\n",
    "    problems=[OPTIMIZATION_PROBLEM.name()],\n",
    "    dataset_subsets=True,\n",
    "    random_state=RNG_SEED\n",
    ")\n",
    "\n",
    "pop_features, indiv_features, target = next(iter(train_data_loader))\n",
    "lstm_model = LSTMClassifier(\n",
    "    input_dim=np.shape(pop_features)[2],\n",
    "    aux_input_dim=np.shape(indiv_features)[1],\n",
    "    num_labels=len(actual_labels),\n",
    "    hidden_dim=LSTM_HIDDEN_DIM,\n",
    "    num_layers=LSTM_NUM_LAYERS,\n",
    "    dropout=LSTM_DROPOUT\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lstm_model_filename = f\"./lstm_model.pt\"\n",
    "\n",
    "if execute_training:\n",
    "    lstm_model.to(device)\n",
    "    nn_train(\n",
    "        model=lstm_model,\n",
    "        train_data_loader=train_data_loader,\n",
    "        val_data_loader=val_data_loader,\n",
    "        epochs=EPOCHS,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        model_filename=lstm_model_filename,\n",
    "        verbal=True)\n",
    "else:\n",
    "    lstm_model = torch.load(lstm_model_filename, map_location=torch.device(device))\n",
    "    lstm_model.to(device)\n",
    "    if os.path.exists('loss_plot.png'):\n",
    "        loss_plot = np.asarray(Image.open('loss_plot.png'))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test(\n",
    "    model=lstm_model,\n",
    "    test_data_loader=test_data_loader,\n",
    "    device=device,\n",
    "    labels=actual_labels,\n",
    "    show_classification_report=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, val_data_loader, test_data_loader, actual_labels = get_data_loaders(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    batch_size=100,\n",
    "    val_size=VAL_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "    n_pca_components=N_PCA_COMPONENTS,\n",
    "    problems=[OPTIMIZATION_PROBLEM.name()],\n",
    "    dataset_subsets=True,\n",
    "    nn_type=NNType.LINEAR,\n",
    "    random_state=RNG_SEED\n",
    ")\n",
    "\n",
    "feature_vector, target = next(iter(train_data_loader))\n",
    "\n",
    "linear_model = LinearClassifier(\n",
    "    input_dim=np.shape(feature_vector)[1],\n",
    "    num_labels=len(actual_labels),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "linear_model_filename = f\"./linear_model.pt\"\n",
    "\n",
    "if execute_training:\n",
    "    linear_model.to(device)\n",
    "    nn_train(\n",
    "        model=linear_model,\n",
    "        train_data_loader=train_data_loader,\n",
    "        val_data_loader=val_data_loader,\n",
    "        epochs=200,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        model_filename=linear_model_filename,\n",
    "        nn_type=NNType.LINEAR,\n",
    "        verbal=True)\n",
    "else:\n",
    "    linear_model = torch.load(linear_model_filename, map_location=torch.device(device))\n",
    "    linear_model.to(device)\n",
    "    if os.path.exists('loss_plot.png'):\n",
    "        loss_plot = np.asarray(Image.open('loss_plot.png'))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(loss_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test(\n",
    "    model=linear_model,\n",
    "    test_data_loader=test_data_loader,\n",
    "    device=device,\n",
    "    nn_type=NNType.LINEAR,\n",
    "    labels=actual_labels,\n",
    "    show_classification_report=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MetaheuristicSimilarityAnalyzer.import_from_pkl(\"./archive/target_performance_similarity/06-28_10.33.39_FA_Schwefel/msa_obj\")\n",
    "combined_feature_vectors = []\n",
    "markers = []\n",
    "actual_labels = []\n",
    "subset_idx = 1\n",
    "\n",
    "for vector in analyzer.target_feature_vectors[subset_idx]:\n",
    "    combined_feature_vectors.append(vector)\n",
    "    markers.append(\"o\")\n",
    "    actual_labels.append(0)\n",
    "for vector in analyzer.optimized_solutions_feature_vectors[subset_idx]:\n",
    "    combined_feature_vectors.append(vector)\n",
    "    markers.append(\"x\")\n",
    "    actual_labels.append(1)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_feature_vectors = pca.fit_transform(combined_feature_vectors)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=RNG_SEED)\n",
    "predicted_labels = kmeans.fit_predict(combined_feature_vectors)\n",
    "\n",
    "# classification report\n",
    "print(sklearn.metrics.classification_report(actual_labels, predicted_labels))\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(actual_labels, predicted_labels)\n",
    "cm_display = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "print(predicted_labels)\n",
    "\n",
    "# scatter plot\n",
    "colors = [\"orange\", \"blue\"]\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "for idx, (location, label, marker) in enumerate(zip(pca_feature_vectors, predicted_labels, markers)):\n",
    "    ax.scatter3D(location[0], location[1], location[2], color = colors[label], marker=markers[idx], s=30)\n",
    "\n",
    "ax.set_xlabel(\"PCA_1\")\n",
    "ax.set_ylabel(\"PCA_2\")\n",
    "ax.set_zlabel(\"PCA_3\")\n",
    "plt.title(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_feature_vectors = False\n",
    "analyzer = MetaheuristicSimilarityAnalyzer.import_from_pkl(\"./archive/target_performance_similarity/07-30_08.14.05_WVCPSO_Schwefel/msa_obj\")\n",
    "combined_feature_vectors = []\n",
    "markers = []\n",
    "actual_labels = []\n",
    "\n",
    "if average_feature_vectors:\n",
    "    for array in analyzer.target_feature_vectors:\n",
    "        combined_feature_vectors.append(np.mean(array, axis=0))\n",
    "        markers.append(\"o\")\n",
    "        actual_labels.append(0)\n",
    "    for array in analyzer.optimized_solutions_feature_vectors:\n",
    "        combined_feature_vectors.append(np.mean(array, axis=0))\n",
    "        markers.append(\"x\")\n",
    "        actual_labels.append(1)\n",
    "else:\n",
    "    for array in analyzer.target_feature_vectors:\n",
    "        for vector in array:\n",
    "            combined_feature_vectors.append(vector)\n",
    "            markers.append(\"o\")\n",
    "            actual_labels.append(0)\n",
    "    for array in analyzer.optimized_solutions_feature_vectors:\n",
    "        for vector in array:\n",
    "            combined_feature_vectors.append(vector)\n",
    "            markers.append(\"x\")\n",
    "            actual_labels.append(1)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_feature_vectors = pca.fit_transform(combined_feature_vectors)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=RNG_SEED)\n",
    "predicted_labels = kmeans.fit_predict(combined_feature_vectors)\n",
    "\n",
    "# classification report\n",
    "print(sklearn.metrics.classification_report(actual_labels, predicted_labels))\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(actual_labels, predicted_labels)\n",
    "cm_display = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "print(predicted_labels)\n",
    "\n",
    "# scatter plot\n",
    "colors = [\"orange\", \"blue\"]\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "for idx, (location, label, marker) in enumerate(zip(pca_feature_vectors, predicted_labels, markers)):\n",
    "    ax.scatter3D(location[0], location[1], location[2], color = colors[label], marker=markers[idx], s=30)\n",
    "\n",
    "ax.set_xlabel(\"PCA_1\")\n",
    "ax.set_ylabel(\"PCA_2\")\n",
    "ax.set_zlabel(\"PCA_3\")\n",
    "plt.title(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise feature vectors visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_feature_vectors = True\n",
    "analyzer = MetaheuristicSimilarityAnalyzer.import_from_pkl(\"./archive/target_performance_similarity/06-28_10.33.39_FA_Schwefel/msa_obj\")\n",
    "combined_feature_vectors = []\n",
    "actual_labels = []\n",
    "colors = []\n",
    "\n",
    "if average_feature_vectors:\n",
    "    number_labels = [*range(analyzer.comparisons)]\n",
    "    color = [np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0)]\n",
    "    for array in analyzer.target_feature_vectors:\n",
    "        colors.append(color) \n",
    "        combined_feature_vectors.append(np.mean(array, axis=0))\n",
    "        actual_labels.append(0)\n",
    "    color = [np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0)]\n",
    "    for array in analyzer.optimized_solutions_feature_vectors:\n",
    "        colors.append(color) \n",
    "        combined_feature_vectors.append(np.mean(array, axis=0))\n",
    "        actual_labels.append(1)\n",
    "else:\n",
    "    #number_labels = [*range(analyzer.meta_ga.num_runs * analyzer.comparisons)]\n",
    "    number_labels = [*range(150 * analyzer.comparisons)]\n",
    "    color = [np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0)]\n",
    "    for array in analyzer.target_feature_vectors:\n",
    "        for vector in array:\n",
    "            colors.append(color)\n",
    "            combined_feature_vectors.append(vector)\n",
    "            actual_labels.append(0)\n",
    "    color = [np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0)]\n",
    "    for array in analyzer.optimized_solutions_feature_vectors:\n",
    "        for vector in array:\n",
    "            colors.append(color)\n",
    "            combined_feature_vectors.append(vector)\n",
    "            actual_labels.append(1)\n",
    "\n",
    "#colors.extend(colors)\n",
    "\n",
    "number_labels.extend(number_labels)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_feature_vectors = pca.fit_transform(combined_feature_vectors)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# scatter plot\n",
    "fig = plt.figure(figsize=(30, 20))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "for idx, location in enumerate(pca_feature_vectors):\n",
    "    ax.scatter3D(location[0], location[1], location[2], color = colors[idx], s=30)\n",
    "    ax.text(location[0], location[1], location[2], str(number_labels[idx]), size=10, zorder=10, color='k')\n",
    "\n",
    "ax.set_xlabel(\"PCA_1\")\n",
    "ax.set_ylabel(\"PCA_2\")\n",
    "ax.set_zlabel(\"PCA_3\")\n",
    "plt.title(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors & SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_feature_vectors = False\n",
    "analyzer = MetaheuristicSimilarityAnalyzer.import_from_pkl(\"./archive/target_performance_similarity/07-30_08.14.05_WVCPSO_Schwefel/msa_obj\")\n",
    "combined_feature_vectors = []\n",
    "actual_labels = []\n",
    "\n",
    "if average_feature_vectors:\n",
    "    for array in analyzer.target_feature_vectors:\n",
    "        combined_feature_vectors.append(np.mean(array, axis=0))\n",
    "        actual_labels.append(0)\n",
    "    for array in analyzer.optimized_solutions_feature_vectors:\n",
    "        combined_feature_vectors.append(np.mean(array, axis=0))\n",
    "        actual_labels.append(1)\n",
    "else:\n",
    "    for array in analyzer.target_feature_vectors:\n",
    "        for vector in array:\n",
    "            _vector = sklearn.preprocessing.minmax_scale(vector, feature_range=(0, 1))\n",
    "            combined_feature_vectors.append(_vector)\n",
    "            actual_labels.append(0)\n",
    "    for array in analyzer.optimized_solutions_feature_vectors:\n",
    "        for vector in array:\n",
    "            _vector = sklearn.preprocessing.minmax_scale(vector, feature_range=(0, 1))\n",
    "            combined_feature_vectors.append(_vector)\n",
    "            actual_labels.append(1)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_feature_vectors, actual_labels, test_size = 0.2, shuffle=True)\n",
    "\n",
    "# K-SVM classifier\n",
    "k_svm = svm.SVC(kernel='rbf') \n",
    "k_svm.fit(X_train, y_train)\n",
    "svm_training_score = k_svm.score(X_train, y_train) \n",
    "svm_test_score = k_svm.score(X_test, y_test)\n",
    "print(\"SVM train:\", svm_training_score)\n",
    "print(\"SVM test:\", svm_test_score)\n",
    "\n",
    "# kNN classifier\n",
    "knc = KNeighborsClassifier(n_neighbors = 10) \n",
    "knc.fit(X_train, y_train)\n",
    "knn_training_score = knc.score(X_train, y_train) \n",
    "knn_test_score = knc.score(X_test, y_test) \n",
    "print(\"KNN train:\", knn_training_score)\n",
    "print(\"KNN test:\", knn_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of feature vectors with metaheuristics constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./dataset\"\n",
    "feature_vectors_1 = []\n",
    "feature_vectors_2 = []\n",
    "for idx, algorithm in enumerate(os.listdir(dataset_path)):\n",
    "    for problem in os.listdir(os.path.join(dataset_path, algorithm)):\n",
    "        runs = os.listdir(os.path.join(dataset_path, algorithm, problem))\n",
    "        runs.sort()\n",
    "        for run in runs:\n",
    "            run_path = os.path.join(dataset_path, algorithm, problem, run)\n",
    "            srd = SingleRunData.import_from_json(run_path)\n",
    "            feature_vector = srd.get_combined_feature_vector()\n",
    "\n",
    "            if idx == 0:\n",
    "                feature_vectors_1.append(feature_vector)\n",
    "            else:\n",
    "                feature_vectors_2.append(feature_vector)\n",
    "\n",
    "combined_feature_vectors = []\n",
    "markers = []\n",
    "actual_labels = []\n",
    "number_labels = [*range(150)]\n",
    "number_labels.extend(number_labels)\n",
    "\n",
    "for array in feature_vectors_1:\n",
    "        combined_feature_vectors.append(array)\n",
    "        markers.append(\"o\")\n",
    "        actual_labels.append(0)\n",
    "for array in feature_vectors_2:\n",
    "        combined_feature_vectors.append(array)\n",
    "        markers.append(\"x\")\n",
    "        actual_labels.append(1)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_feature_vectors = pca.fit_transform(combined_feature_vectors)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)#, random_state=RNG_SEED)\n",
    "predicted_labels = kmeans.fit_predict(combined_feature_vectors)\n",
    "\n",
    "# classification report\n",
    "print(sklearn.metrics.cluster.adjusted_rand_score(actual_labels, predicted_labels))\n",
    "print(sklearn.metrics.classification_report(actual_labels, predicted_labels))\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(actual_labels, predicted_labels)\n",
    "cm_display = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "print(predicted_labels)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_feature_vectors, actual_labels, test_size = 0.2, shuffle=True)\n",
    "\n",
    "# K-SVM classifier\n",
    "k_svm = svm.SVC(kernel='rbf') \n",
    "k_svm.fit(X_train, y_train)\n",
    "svm_training_score = k_svm.score(X_train, y_train) \n",
    "svm_test_score = k_svm.score(X_test, y_test)\n",
    "print(\"SVM train:\", svm_training_score)\n",
    "print(\"SVM test:\", svm_test_score)\n",
    "\n",
    "# kNN classifier\n",
    "knc = KNeighborsClassifier(n_neighbors = 10) \n",
    "knc.fit(X_train, y_train)\n",
    "knn_training_score = knc.score(X_train, y_train) \n",
    "knn_test_score = knc.score(X_test, y_test) \n",
    "print(\"KNN train:\", knn_training_score)\n",
    "print(\"KNN test:\", knn_test_score)\n",
    "\n",
    "# scatter plot\n",
    "colors = [\"orange\", \"blue\"]\n",
    "fig = plt.figure(figsize = (30, 20))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "for idx, (location, label, marker) in enumerate(zip(pca_feature_vectors, predicted_labels, markers)):\n",
    "    ax.scatter3D(location[0], location[1], location[2], color = colors[label], marker=markers[idx], s=30)\n",
    "    ax.text(location[0], location[1], location[2], str(number_labels[idx]), size=10, zorder=10, color='k')\n",
    "\n",
    "ax.set_xlabel(\"PCA_1\")\n",
    "ax.set_ylabel(\"PCA_2\")\n",
    "ax.set_zlabel(\"PCA_3\")\n",
    "plt.title(\"Features\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
