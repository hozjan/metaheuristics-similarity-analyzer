{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niapy.algorithms.basic import (\n",
    "    BatAlgorithm,\n",
    "    FireflyAlgorithm,\n",
    "    ParticleSwarmAlgorithm\n",
    ")\n",
    "from niapy.problems.ackley import Ackley\n",
    "from niapy.problems.sphere import Sphere\n",
    "from niapy.runner import Runner\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pygad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools.ml_tools import get_data_loaders, nn_test, nn_train, LSTM\n",
    "from util.optimization_data import SingleRunData\n",
    "from tools.optimization_tools import optimization_runner\n",
    "import meta_ga\n",
    "\n",
    "from util.constants import (\n",
    "    RNG_SEED,\n",
    "    DATASET_PATH,\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    POP_SIZE,\n",
    "    MAX_EVALS,\n",
    "    MAX_ITERS,\n",
    "    NUM_RUNS,\n",
    "    POP_DIVERSITY_METRICS,\n",
    "    INDIV_DIVERSITY_METRICS,\n",
    "    OPTIMIZATION_PROBLEM,\n",
    "    GENE_SPACES\n",
    ")\n",
    "\n",
    "execute_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance = pygad.load(\"./meta_ga_obj\")\n",
    "print(ga_instance.best_solutions[-1])\n",
    "print(ga_instance.best_solutions_fitness[-1])\n",
    "\n",
    "algorithms = meta_ga.solution_to_algorithm_attributes(ga_instance.best_solutions[-1], GENE_SPACES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_problem = Ackley(dimension=20)\n",
    "test_algorithms = [\n",
    "    BatAlgorithm(population_size=POP_SIZE, alpha=0.99, gamma=0.9, pulse_rate=0.9, loudness=0.9),\n",
    "    FireflyAlgorithm(population_size=POP_SIZE, alpha=1.0, beta0=1.0, gamma=0.0, theta=0.97),\n",
    "    ParticleSwarmAlgorithm(population_size=POP_SIZE, c1=1.0, c2=1.0, w=0.9),\n",
    "]\n",
    "\n",
    "problem = OPTIMIZATION_PROBLEM\n",
    "\n",
    "for algorithm in test_algorithms:\n",
    "    optimization_runner(\n",
    "        algorithm,\n",
    "        problem,\n",
    "        NUM_RUNS,\n",
    "        DATASET_PATH,\n",
    "        POP_DIVERSITY_METRICS,\n",
    "        INDIV_DIVERSITY_METRICS,\n",
    "        max_iters=MAX_ITERS,\n",
    "        rng_seed=RNG_SEED,\n",
    "        parallel_processing=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        pop_metrics = SingleRunData.import_from_json(run_path).get_pop_diversity_metrics_values(normalize=True)\n",
    "        pop_metrics.plot(title=\" \".join([algorithm, problem]), figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best fitness value convergence comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_dict = {}\n",
    "max_len = 0\n",
    "\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        convergence = SingleRunData.import_from_json(run_path).get_best_fitness_values(False)\n",
    "        if len(convergence) > max_len:\n",
    "            max_len = len(convergence)\n",
    "        convergence_dict[\"_\".join([algorithm, problem])] = convergence\n",
    "\n",
    "for key in convergence_dict:\n",
    "    convergence = convergence_dict[key]\n",
    "    convergence = np.append(convergence, [convergence[-1]] * (max_len - len(convergence)))\n",
    "    convergence_dict[key] = convergence\n",
    "\n",
    "convergence_dict = pd.DataFrame.from_dict(convergence_dict)\n",
    "convergence_dict.plot(title=\" \".join([algorithm, problem]), figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual diversity metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd = SingleRunData.import_from_json(run_path)\n",
    "        indiv_metrics = SingleRunData.import_from_json(run_path).get_indiv_diversity_metrics_values(normalize=True)\n",
    "        indiv_metrics.plot(title=\" \".join([algorithm, problem]), figsize=(20,5), kind=\"bar\")\n",
    "        pca = PCA(n_components=indiv_metrics.to_numpy().shape[1])\n",
    "        principal_components = pca.fit_transform(indiv_metrics)\n",
    "        fig = plt.figure(figsize = (10, 7))\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        ax.scatter3D(principal_components[:,0], principal_components[:,1], principal_components[:,2], color = \"green\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity metrics euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srd = []\n",
    "for algorithm in os.listdir(DATASET_PATH):\n",
    "    for problem in os.listdir(os.path.join(DATASET_PATH, algorithm)):\n",
    "        runs = os.listdir(os.path.join(DATASET_PATH, algorithm, problem))\n",
    "        run_path = os.path.join(DATASET_PATH, algorithm, problem, runs[0])\n",
    "        srd.append(SingleRunData.import_from_json(run_path))\n",
    "\n",
    "print(srd[0].diversity_metrics_euclidean_distance(srd[1]))\n",
    "print(srd[0].diversity_metrics_euclidean_distance(srd[1], include_fitness_convergence=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(\"CPUs: \", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, val_data_loader, test_data_loader, labels = get_data_loaders(DATASET_PATH, BATCH_SIZE, problems=[\"Sphere\"], random_state=RNG_SEED)\n",
    "\n",
    "pop_features, indiv_features, target = next(iter(train_data_loader))\n",
    "model = LSTM(np.shape(pop_features)[2], np.shape(indiv_features)[1], len(labels))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_file_name = f\"./lstm_model.pt\"\n",
    "\n",
    "if execute_training:\n",
    "    model.to(device)\n",
    "    nn_train(model, train_data_loader, val_data_loader, EPOCHS, loss_fn, optimizer, device, model_file_name, patience=100, verbal=True)\n",
    "else:\n",
    "    model = torch.load(model_file_name, map_location=torch.device(device))\n",
    "    model.to(device)\n",
    "    if os.path.exists('loss_plot.png'):\n",
    "        loss_plot = np.asarray(Image.open('loss_plot.png'))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test(model, test_data_loader, device, labels=labels, show_classification_report=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
