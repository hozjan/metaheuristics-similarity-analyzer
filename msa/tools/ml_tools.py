import torch
from torch import nn
from torch.optim.optimizer import Optimizer
from torch import device
from torch.utils import data
import pandas as pd
import seaborn as sb
import sklearn.model_selection
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    KFold,
)
from sklearn import svm
from matplotlib import pyplot as plt
from enum import Enum
import os
import numpy as np

from msa.util.optimization_data import SingleRunData

__all__ = [
    "NNType",
    "data_generator",
    "LSTMClassifier",
    "LinearClassifier",
    "get_data_loaders",
    "nn_train",
    "nn_test",
    "svm_and_knn_classification",
]


class NNType(Enum):
    LSTM = 0
    LINEAR = 1


class data_generator(torch.utils.data.Dataset):
    def __init__(self, data_path_list, labels, n_pca_components, nn_type) -> None:
        super().__init__()
        self.data_path_list = data_path_list
        self.labels = labels
        self.n_pca_components = n_pca_components
        self.nn_type = nn_type

    def __len__(self):
        return len(self.data_path_list)

    def __getitem__(self, index):
        run = SingleRunData.import_from_json(self.data_path_list[index])
        if run.algorithm_name is not None:
            alg_abbr = run.algorithm_name[1]
        else:
            alg_abbr = ""

        if self.nn_type == NNType.LSTM:
            pop_metrics = run.get_pop_diversity_metrics_values(standard_scale=True).to_numpy()
            indiv_metrics = run.get_indiv_diversity_metrics_values(standard_scale=True).to_numpy()

            pca = PCA(n_components=self.n_pca_components)
            transformed_indiv_metrics = pca.fit_transform(indiv_metrics).flatten(order="F")

            return (
                torch.from_numpy(pop_metrics).float(),
                torch.from_numpy(transformed_indiv_metrics).float(),
                torch.tensor(self.labels.index(alg_abbr)),
            )
        elif self.nn_type == NNType.LINEAR:
            feature_vector = run.get_feature_vector(standard_scale=True)
            return (
                torch.from_numpy(feature_vector).float(),
                torch.tensor(self.labels.index(alg_abbr)),
            )


class LSTMClassifier(nn.Module):
    def __init__(
        self,
        input_dim,
        aux_input_dim,
        num_labels,
        hidden_dim=256,
        num_layers=3,
        dropout=0.3,
    ) -> None:
        super().__init__()

        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout,
        )
        self.fc = nn.Linear(hidden_dim + aux_input_dim, num_labels)

    def forward(self, x, aux):
        lstm_out, (h_n, c_n) = self.lstm(x)
        features_0 = lstm_out[:, -1]
        features = torch.concat([features_0, aux], dim=1)
        out = self.fc(features)

        return features, out


class LinearClassifier(nn.Module):
    def __init__(self, input_dim, num_labels) -> None:
        super().__init__()
        self.fc = nn.Linear(input_dim, num_labels)

    def forward(self, x):
        out = self.fc(x)
        return out


def get_data_loaders(
    dataset_path: str,
    batch_size: int,
    val_size: float = 0.2,
    test_size: float = 0.2,
    n_pca_components: int = 3,
    problems: list[str] | None = None,
    dataset_subsets: bool = False,
    nn_type: NNType = NNType.LSTM,
    random_state: int | None = None,
):
    r"""Get dataloaders for NN training, validation and testing.

    Args:
        dataset_path (str): Path to the root folder containing optimization data.
        batch_size (int): Batch size of the data loaders.
        val_size (Optional[float]): Proportion of the dataset used for validation.
        test_size (Optional[float]): Proportion of the dataset used for testing.
        n_pca_components (Optional[int]): Number of PCA components to use per learning sample.
        problems (Optional[list[str]]): Names of the optimization problems to include in the dataset of the loaders.
            Includes all if not provided.
        dataset_subsets (Optional[bool]): Set to true if dataset has subsets (false by default).
        nn_type (Optional[NNType]): Determines the format of data generated by the dataset.
        random_state (Optional[int]): Random seed for dataset shuffle, provide for reproducible results.

    Returns:
        Dataloader: train data loader
        Dataloader: validation data loader
        Dataloader: test data loader
        Array: class labels

    Raises:
        ValueError: Provided attributes yield an empty dataset.
    """
    dataset_paths = []
    labels = []
    dataset_subset_paths = []
    if dataset_subsets:
        for subset in os.listdir(dataset_path):
            dataset_subset_paths.append(os.path.join(dataset_path, subset))
    else:
        dataset_subset_paths.append(dataset_path)

    for dataset_path in dataset_subset_paths:
        for algorithm in os.listdir(dataset_path):
            if algorithm not in labels:
                labels.append(algorithm)
            for problem in os.listdir(os.path.join(dataset_path, algorithm)):
                if problems is not None and problem not in problems:
                    continue
                for run in os.listdir(os.path.join(dataset_path, algorithm, problem)):
                    dataset_paths.append(os.path.join(dataset_path, algorithm, problem, run))

    if len(dataset_paths) == 0:
        raise ValueError(
            "Provided combination of parameters resulted in an empty dataset. Check your `dataset_path` and `problems`."
        )

    x_train, x_test = sklearn.model_selection.train_test_split(
        dataset_paths, test_size=test_size, shuffle=True, random_state=random_state
    )
    x_train, x_val = sklearn.model_selection.train_test_split(
        x_train,
        test_size=val_size / (1.0 - test_size),
        shuffle=True,
        random_state=random_state,
    )

    _cpu_count = os.cpu_count()
    if _cpu_count is None:
        _cpu_count = 1

    train_dataset = data_generator(
        data_path_list=x_train,
        labels=labels,
        n_pca_components=n_pca_components,
        nn_type=nn_type,
    )
    train_data_loader = data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        pin_memory=True,
        num_workers=_cpu_count,
    )

    val_dataset = data_generator(
        data_path_list=x_val,
        labels=labels,
        n_pca_components=n_pca_components,
        nn_type=nn_type,
    )
    val_data_loader = data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=True,
        pin_memory=True,
        num_workers=_cpu_count,
    )

    test_dataset = data_generator(
        data_path_list=x_test,
        labels=labels,
        n_pca_components=n_pca_components,
        nn_type=nn_type,
    )
    test_data_loader = data.DataLoader(
        test_dataset,
        batch_size=1,
        shuffle=True,
        pin_memory=True,
        num_workers=_cpu_count,
    )

    return train_data_loader, val_data_loader, test_data_loader, labels


def nn_train(
    model: nn.Module,
    train_data_loader: data.DataLoader,
    val_data_loader: data.DataLoader,
    epochs: int,
    loss_fn: nn.Module,
    optimizer: Optimizer,
    device: device,
    model_filename: str,
    nn_type: NNType = NNType.LSTM,
    patience: float = np.inf,
    verbal: bool = False,
):
    loss_values = []
    val_loss_values = []
    acc_values = []
    val_acc_values = []
    best_loss = 1.0
    trial_counter = 0

    for epoch in range(epochs):
        _loss_values = []
        _val_loss_values = []
        _acc_values = []
        _val_acc_values = []

        model.train()
        for batch in train_data_loader:
            if nn_type == NNType.LSTM:
                pop_features, indiv_features, target = batch

                target = target.to(device)
                pop_features = pop_features.to(device)
                indiv_features = indiv_features.to(device)

                _, pred = model(pop_features, indiv_features)
            elif nn_type == NNType.LINEAR:
                feature_vector, target = batch

                target = target.to(device)
                feature_vector = feature_vector.to(device)

                pred = model(feature_vector)

            loss = loss_fn(pred, target)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            y_pred = torch.argmax(pred, dim=1).cpu().numpy()
            y_target = target.cpu().numpy()

            _acc_values.append(accuracy_score(y_target, y_pred))
            _loss_values.append(loss.item())

        model.eval()
        with torch.no_grad():
            for batch in val_data_loader:
                if nn_type == NNType.LSTM:
                    pop_features, indiv_features, target = batch

                    target = target.to(device)
                    pop_features = pop_features.to(device)
                    indiv_features = indiv_features.to(device)

                    _, pred = model(pop_features, indiv_features)
                elif nn_type == NNType.LINEAR:
                    feature_vector, target = batch

                    target = target.to(device)
                    feature_vector = feature_vector.to(device)

                    pred = model(feature_vector)

                loss = loss_fn(pred, target)

                y_pred = torch.argmax(pred, dim=1).cpu().numpy()
                y_target = target.cpu().numpy()

                _val_acc_values.append(accuracy_score(y_target, y_pred))
                _val_loss_values.append(loss.item())

        acc_values.append(np.mean(_acc_values))
        val_acc_values.append(np.mean(_val_acc_values))
        loss_values.append(np.mean(_loss_values))
        val_loss_values.append(np.mean(_val_loss_values))

        if verbal:
            print(
                f"""epoch: {epoch + 1}, loss: {loss_values[-1] :.10f}, val_loss: {val_loss_values[-1] :.10f},
                |_ acc: {acc_values[-1] :.10f}, val_acc: {val_acc_values[-1] :.10f}"""
            )

        if val_loss_values[-1] < best_loss:
            trial_counter = 0
            best_loss = val_loss_values[-1]
            torch.save(model, model_filename)
            if verbal:
                print(f"Saving model with loss: {best_loss :.10f}")
        else:
            trial_counter += 1
            if trial_counter >= patience:
                if verbal:
                    print(f"Early stopping after {epoch + 1} epochs")
                break

    if verbal:
        x = [*range(1, len(loss_values) + 1)]
        plt.plot(x, loss_values, label="train loss")
        plt.plot(x, val_loss_values, label="val loss")
        plt.legend()
        plt.show()
        plt.plot(x, acc_values, label="train acc")
        plt.plot(x, val_acc_values, label="val acc")
        plt.legend()
        plt.show()


def nn_test(
    model: nn.Module,
    test_data_loader: data.DataLoader,
    device: device,
    nn_type: NNType = NNType.LSTM,
    labels: list[str] | None = None,
    show_classification_report: bool = False,
):
    model.eval()

    y_pred = []
    y_target = []

    for batch in test_data_loader:
        if nn_type == NNType.LSTM:
            pop_features, indiv_features, target = batch

            target = target.to(device)
            pop_features = pop_features.to(device)
            indiv_features = indiv_features.to(device)

        elif nn_type == NNType.LINEAR:
            feature_vector, target = batch

            target = target.to(device)
            feature_vector = feature_vector.to(device)

        with torch.no_grad():
            if nn_type == NNType.LSTM:
                _, pred = model(pop_features, indiv_features)
            elif nn_type == NNType.LINEAR:
                pred = model(feature_vector)

            y_pred.append(torch.argmax(pred).cpu().numpy())
            y_target.append(target.cpu().numpy()[0])

    if labels is not None:
        cf_matrix = confusion_matrix(y_target, y_pred)
        df_cm = pd.DataFrame(cf_matrix, index=[i for i in labels], columns=[i for i in labels])
        plt.figure(figsize=(12, 7))
        sb.heatmap(df_cm, annot=True)

    if show_classification_report:
        print(classification_report(y_target, y_pred))

    return accuracy_score(y_target, y_pred)


def svm_and_knn_classification(
    dataset_path: str,
    repetitions: int,
    bar_chart_filename: str | None = None,
    box_plot_filename: str | None = None,
):
    r"""Evaluate similarity of metaheuristics with SVM and KNN classifiers based on feature vectors.
    Based on assumption should models perform worse when distinguishing metaheuristics with higher similarity.
    To maximize metaheuristics similarity metric `1-accuracy` is used as similarity metric.

    Args:
        dataset_path (str): Path to the root folder containing optimization data arranged into subsets of comparisons
            of MetaheuristicSimilarityAnalyzer.
        repetitions (int): Number of training repetitions to get the average 1-accuracy score from.
        bar_chart_filename (Optional[str]): Filename of the bar charts showing metric 1-accuracy values of the models
            per MetaheuristicSimilarityAnalyzer comparison.
        box_plot_filename (Optional[str]): Filename of the box plot showing metric 1-accuracy values of the models for
            all MetaheuristicSimilarityAnalyzer comparisons.

    Returns:
        1-accuracy scores (dict[str, numpy.ndarray[float]]): Dictionary containing 1-accuracy scores for train and test
            subsets of both models.
    """
    alg_1_label = ""
    alg_2_label = ""
    _k_svm_scores = []
    _knn_scores = []
    subsets = os.listdir(dataset_path)

    for idx in range(len(subsets)):
        subset = f"{idx}_subset"
        subset_k_svm_scores = []
        subset_knn_scores = []
        feature_vectors = []
        actual_labels = []
        for idx, algorithm in enumerate(os.listdir(os.path.join(dataset_path, subset))):
            if idx == 0 and alg_1_label == "":
                alg_1_label = algorithm
            elif idx == 1 and alg_2_label == "":
                alg_2_label = algorithm

            for problem in os.listdir(os.path.join(dataset_path, subset, algorithm)):
                runs = os.listdir(os.path.join(dataset_path, subset, algorithm, problem))
                runs.sort()
                for run in runs:
                    run_path = os.path.join(dataset_path, subset, algorithm, problem, run)
                    srd = SingleRunData.import_from_json(run_path)
                    feature_vector = srd.get_feature_vector(standard_scale=True)
                    feature_vectors.append(feature_vector)
                    actual_labels.append(idx)

        for _ in range(repetitions):
            # train test split
            X_train, X_test, y_train, y_test = train_test_split(
                feature_vectors, actual_labels, test_size=0.2, shuffle=True
            )

            scaler = StandardScaler()
            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

            # K-SVM classifier
            # define the parameter grid
            param_grid = {
                "C": [0.001, 0.01, 0.1, 1, 10, 100, 1000],
                "gamma": [0.0001, 0.001, 0.01, 1, 10, 100, 1000],
            }

            k_svm = svm.SVC(kernel="rbf")
            kf = KFold(n_splits=5, shuffle=True, random_state=None)

            # perform grid search
            grid_search = GridSearchCV(k_svm, param_grid, cv=kf, n_jobs=-1)
            grid_search.fit(X_train, y_train)

            _C = grid_search.best_params_.get("C")
            _gamma = grid_search.best_params_.get("gamma")
            k_svm = svm.SVC(
                kernel="rbf",
                C=0 if _C is None else _C,
                gamma=0 if _gamma is None else _gamma,
            )
            k_svm.fit(X_train, y_train)
            svm_training_score = k_svm.score(X_train, y_train)
            svm_test_score = k_svm.score(X_test, y_test)
            tmp = []
            tmp.append(1.0 - svm_training_score)
            tmp.append(1.0 - svm_test_score)
            subset_k_svm_scores.append(tmp)

            # kNN classifier
            # define the parameter grid
            param_grid = {"n_neighbors": np.arange(1, min(50, round(len(y_train) / 3))).tolist()}

            knn = KNeighborsClassifier()
            kf = KFold(n_splits=5, shuffle=True, random_state=None)

            # perform grid search
            grid_search = GridSearchCV(knn, param_grid, cv=kf, n_jobs=-1)
            grid_search.fit(X_train, y_train)

            _n_neighbors = grid_search.best_params_.get("n_neighbors")
            if _n_neighbors is None:
                _n_neighbors = 0
            knn = KNeighborsClassifier(n_neighbors=_n_neighbors)
            knn.fit(X_train, y_train)
            knn_training_score = knn.score(X_train, y_train)
            knn_test_score = knn.score(X_test, y_test)
            tmp = []
            tmp.append(1.0 - knn_training_score)
            tmp.append(1.0 - knn_test_score)
            subset_knn_scores.append(tmp)

        _k_svm_scores.append(np.mean(subset_k_svm_scores, axis=0))
        _knn_scores.append(np.mean(subset_knn_scores, axis=0))

    k_svm_scores = np.array(_k_svm_scores)
    knn_scores = np.array(_knn_scores)

    bar_width = 0.35
    (
        fig,
        ax,
    ) = plt.subplots(2, 1, figsize=(15, 10))
    fig.subplots_adjust(hspace=0.5)

    # bar charts
    if bar_chart_filename is not None:
        index = np.arange(1, len(k_svm_scores[:, 0]) + 1)
        low = np.min(k_svm_scores)
        high = np.max(k_svm_scores)
        ax[0].bar(index, k_svm_scores[:, 0], bar_width, label="train")
        ax[0].bar(index + bar_width, k_svm_scores[:, 1], bar_width, label="test")
        ax[0].set_title(f"SVM {alg_1_label} - {alg_2_label}", fontsize=22, pad=10)
        ax[0].set_xlabel("configuration", fontsize=19, labelpad=10)
        ax[0].set_ylabel("1-accuracy", fontsize=19, labelpad=10)
        ax[0].tick_params(axis="x", labelsize=19, rotation=45)
        ax[0].tick_params(axis="y", labelsize=19)
        ax[0].legend(fontsize=15)
        ax[0].xaxis.set_ticks(index + bar_width / 2, index)
        ax[0].set_ylim(low - 0.5 * (high - low), high + 0.5 * (high - low))
        ax[0].set_xlim(
            ax[0].patches[0].get_x() / 2,
            ax[0].patches[-1].get_x() + ax[0].patches[-1].get_width() * 2,
        )
        ax[0].grid(axis="y", color="gray", linestyle="--", linewidth=0.7)
        ax[0].set_axisbelow(True)

        low = np.min(knn_scores)
        high = np.max(knn_scores)
        ax[1].bar(index, knn_scores[:, 0], bar_width, label="train")
        ax[1].bar(index + bar_width, knn_scores[:, 1], bar_width, label="test")
        ax[1].set_title(f"KNN {alg_1_label} - {alg_2_label}", fontsize=22, pad=10)
        ax[1].set_xlabel("configuration", fontsize=19, labelpad=10)
        ax[1].set_ylabel("1-accuracy", fontsize=19, labelpad=10)
        ax[1].tick_params(axis="x", labelsize=19, rotation=45)
        ax[1].tick_params(axis="y", labelsize=19)
        ax[1].legend(fontsize=15)
        ax[1].xaxis.set_ticks(index + bar_width / 2, index)
        ax[1].set_ylim(low - 0.5 * (high - low), high + 0.5 * (high - low))
        ax[1].set_xlim(
            ax[1].patches[0].get_x() / 2,
            ax[1].patches[-1].get_x() + ax[1].patches[-1].get_width() * 2,
        )
        ax[1].grid(axis="y", color="gray", linestyle="--", linewidth=0.7)
        ax[1].set_axisbelow(True)

        fig.savefig(bar_chart_filename, bbox_inches="tight")

    # box plots
    if box_plot_filename is not None:
        (
            fig,
            ax,
        ) = plt.subplots(1, 2, figsize=(15, 5))
        fig.subplots_adjust(wspace=0.3)
        labels = ["train", "test"]

        ax[0].boxplot(k_svm_scores)
        ax[0].set_xticks(ticks=np.arange(1, len(labels) + 1), labels=labels)
        ax[0].tick_params(axis="both", labelsize=19)
        ax[0].set_title(f"SVM  {alg_1_label} - {alg_2_label}", fontsize=22, pad=15)
        ax[0].tick_params(axis="both", labelsize=19)
        ax[0].set_ylabel("1-accuracy", fontsize=19, labelpad=10)

        ax[1].boxplot(knn_scores)
        ax[1].set_xticks(ticks=np.arange(1, len(labels) + 1), labels=labels)
        ax[1].tick_params(axis="both", labelsize=19)
        ax[1].set_title(f"KNN  {alg_1_label} - {alg_2_label}", fontsize=22, pad=15)
        ax[1].tick_params(axis="both", labelsize=19)
        ax[1].set_ylabel("1-accuracy", fontsize=19, labelpad=10)

        fig.savefig(box_plot_filename, bbox_inches="tight")

    accuracy = {
        "svm_train": np.round(k_svm_scores.transpose()[0], 2).tolist(),
        "svm_test": np.round(k_svm_scores.transpose()[1], 2).tolist(),
        "knn_train": np.round(knn_scores.transpose()[0], 2).tolist(),
        "knn_test": np.round(knn_scores.transpose()[1], 2).tolist(),
    }

    return accuracy
